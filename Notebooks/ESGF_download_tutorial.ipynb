{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading from the ESGF archive\n",
    "\n",
    "This Notebook runs through all the steps to download CORDEX data from the Earth System Grid Federation archive, from a single dataset, to multiple ensembles including various models, variables, and experiments. Before you start, check out the 'Before you start' section to ensure you have the appropriate setup to run the code:\n",
    "\n",
    "### CORDEX\n",
    "\n",
    "CORDEX, or the Coordinate Regional Downscaling Experiment, is an internationally coordinated effort to produce high-resolution regional climate model data for several of the world's key regions. Boundary conditions for the regions are provided by an ensemble of General Circulation Models (GCMs), with high-resolution Regional Climate Models (RCMs) handling the dynamics within the region. The project has standardised a number of experiments for each GCM-RCM pair to run, including a historical run and one for each Representative Concentration Pathway (RCP). The full dataset can be browsed manually at https://esgf-data.dkrz.de/search/cordex-dkrz/. For the Pyrenees, the region of interest has the code 'EUR-11'.\n",
    "\n",
    "Even for just a single variable and a handful of experiments, the data available is in the dozens of GBs and hundreds of individual files. For this reason, it is significantly more convenient to download the data we need programmatically. This notebook sets out how we can do that using a handful of useful libraries, notably pyesgf for querying th ESGF database and aiohttp / asyncio for asynchronous downloading of files.\n",
    "\n",
    "### Before you start\n",
    "\n",
    "Before you start, please ensure:\n",
    "\n",
    "- All libraries listed below installed by either pip or conda (installation instructions available in the online documentation)\n",
    "- An ESGF account on the german node: https://esgf-data.dkrz.de\n",
    "- Approved access to the CORDEX datasets. Apply here: https://esg-dn1.nsc.liu.se/ac/subscribe/CORDEX_Research\n",
    "    (you may need to apply twice before your account is flagged approved)\n",
    "- evironment variables saved for:\n",
    "    - ESGF_USERNAME - the ESGF username for your german-node account\n",
    "    - ESGF_PASSWORD - the ESGF password for your german-node account\n",
    "    - DATA_HOME - a local path to the directory in which you want to store this data\n",
    "\n",
    "You can save evironment variables by using either the terminal commands:\n",
    "\n",
    "        export ESGF_USERNAME=myusername\n",
    "        export ESGF_PASSWORD=mypassword\n",
    "        export DATA_HOME=path/to/data\n",
    "        \n",
    "OR save them for all future sessions by copying the above commands into your bash profile (~/.bashrc for unix operating systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'test' from 'libs.download' (/Users/jonniebarnsley/Documents/Python/Field trip/libs/download.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39masyncio\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxarray\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxr\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownload\u001b[39;00m \u001b[39mimport\u001b[39;00m test\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m product\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyesgf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogon\u001b[39;00m \u001b[39mimport\u001b[39;00m LogonManager\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'test' from 'libs.download' (/Users/jonniebarnsley/Documents/Python/Field trip/libs/download.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ssl\n",
    "import pyesgf\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import xarray as xr\n",
    "from libs.download import test\n",
    "from itertools import product\n",
    "from pyesgf.logon import LogonManager\n",
    "from pyesgf.search import SearchConnection\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'libs.download' has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dl\u001b[39m.\u001b[39;49mtest()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'libs.download' has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your query\n",
    "query = {\n",
    "    'project': 'CORDEX',\n",
    "    'domain': 'EUR-11',\n",
    "    'experiment': 'rcp85',\n",
    "    'variable': 'tas',\n",
    "    'time_frequency': 'mon',\n",
    "    'ensemble': 'r1i1p1'\n",
    "}\n",
    "\n",
    "# ensure the following are saved as environment variables\n",
    "USERNAME = os.environ['ESGF_USERNAME']\n",
    "PASSWORD = os.environ['ESGF_PASSWORD']\n",
    "DATA_PATH = os.environ['DATA_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyesgf.search.connection.SearchConnection"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ESGF for number of datasets that satisfy query\n",
    "conn = SearchConnection('http://esgf-data.dkrz.de/esg-search', distrib=True)\n",
    "context = conn.new_context(**query, facets=query.keys())\n",
    "context.hit_count\n",
    "\n",
    "type(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# login to ESGF and generate SSL context\n",
    "myproxy_host = 'esgf-data.dkrz.de'\n",
    "\n",
    "lm = LogonManager()\n",
    "lm.logon(username=USERNAME, password=PASSWORD, hostname=myproxy_host)\n",
    "\n",
    "sslcontext = ssl.create_default_context(purpose=ssl.Purpose.SERVER_AUTH)\n",
    "sslcontext.load_verify_locations(capath=lm.esgf_certs_dir)\n",
    "sslcontext.load_cert_chain(lm.esgf_credentials)\n",
    "\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ssl.SSLContext"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sslcontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cordex.output.EUR-11.CLMcom.MPI-M-MPI-ESM-LR.rcp85.r1i1p1.CCLM4-8-17.v1.mon.tas.v20140515|esgf1.dkrz.de'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate results and check an example dataset to verify all is working as expected\n",
    "results = context.search()\n",
    "example_dataset = results[0]\n",
    "example_dataset.dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://esgf1.dkrz.de/thredds/fileServer/cordex/cordex/output/EUR-11/CLMcom/MPI-M-MPI-ESM-LR/rcp85/r1i1p1/CLMcom-CCLM4-8-17/v1/mon/tas/v20140515/tas_EUR-11_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-CCLM4-8-17_v1_mon_200601-201012.nc'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now an example file within that dataset, including its http download link\n",
    "example_files = example_dataset.file_context().search(ignore_facet_check=True)\n",
    "example_file = example_files[0]\n",
    "example_file.download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "download_ensemble() got an unexpected keyword argument 'ssl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# call download_ensemble on the context generated by your query\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m downloads \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39;49mdownload_ensemble(context, DATA_PATH, ssl\u001b[39m=\u001b[39;49msslcontext, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: download_ensemble() got an unexpected keyword argument 'ssl'"
     ]
    }
   ],
   "source": [
    "# call download_ensemble on the context generated by your query\n",
    "downloads = dl.download_ensemble(context, DATA_PATH, ssl=sslcontext, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: If you're only downloading a handful of variables/experiments, the above code will be perfectly suitable for your needs. The following code blocks are only for circumstances where you want to leave your code running for a very long time (eg overnight) and would like to queue everything up for one big execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying ESGF...\n",
      "found the following datasets matching your queries:\n",
      "\n",
      "project        domain         experiment     variable       time_frequency ensemble        hit_count\n",
      "CORDEX         EUR-11         historical     tas            mon            r1i1p1          48\n",
      "CORDEX         EUR-11         historical     pr             mon            r1i1p1          48\n",
      "CORDEX         EUR-11         rcp26          tas            mon            r1i1p1          23\n",
      "CORDEX         EUR-11         rcp26          pr             mon            r1i1p1          23\n",
      "CORDEX         EUR-11         rcp85          tas            mon            r1i1p1          46\n",
      "CORDEX         EUR-11         rcp85          pr             mon            r1i1p1          46\n"
     ]
    }
   ],
   "source": [
    "# or make multiple queries\n",
    "\n",
    "queries = {\n",
    "    'project': ['CORDEX'],\n",
    "    'domain': ['EUR-11'],\n",
    "    'experiment': ['historical', 'rcp26', 'rcp85'],\n",
    "    'variable': ['tas', 'pr'],\n",
    "    'time_frequency': ['mon'],\n",
    "    'ensemble': ['r1i1p1']\n",
    "}\n",
    "\n",
    "def make_multiple_queries(\n",
    "            queries: dict,\n",
    "            conn: pyesgf.search.connection.SearchConnection\n",
    "):\n",
    "    '''\n",
    "    Takes a queries dictionary with ESGF facets as keys and lists of strings as values.\n",
    "    Prints a table of all configurations of query and the number of datasets that match.\n",
    "    Returns a dictionary of contexts for each configuration.\n",
    "    Has the structure -> dict[config] = context\n",
    "    '''\n",
    "    headers = queries.keys()\n",
    "    values = queries.values()\n",
    "    h = len(headers)\n",
    "    contexts = {}\n",
    "\n",
    "    print('querying ESGF...')\n",
    "    print('found the following datasets matching your queries:\\n')\n",
    "\n",
    "    # print table\n",
    "    print(('{:<14} '*h).format(*headers), 'hit_count')\n",
    "    for config in product(*values):\n",
    "        query = {key: value for key, value in zip(headers, config)}\n",
    "        context = conn.new_context(**query, facets=headers)\n",
    "        contexts[config] = context\n",
    "        hit_count = context.hit_count\n",
    "        print(('{:<14} '*h).format(*config), hit_count)\n",
    "\n",
    "    return contexts\n",
    "\n",
    "# call function\n",
    "contexts = make_multiple_queries(queries=queries, conn=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying ESGF...\n",
      "found the following datasets matching your queries:\n",
      "\n",
      "project        domain         experiment     variable       time_frequency ensemble        hit_count\n",
      "CORDEX         EUR-11         historical     tas            mon            r1i1p1          48\n",
      "CORDEX         EUR-11         historical     pr             mon            r1i1p1          48\n",
      "CORDEX         EUR-11         rcp26          tas            mon            r1i1p1          23\n",
      "CORDEX         EUR-11         rcp26          pr             mon            r1i1p1          23\n",
      "CORDEX         EUR-11         rcp85          tas            mon            r1i1p1          46\n",
      "CORDEX         EUR-11         rcp85          pr             mon            r1i1p1          46\n"
     ]
    }
   ],
   "source": [
    "# and then queue them to download one after the other\n",
    "\n",
    "def download_multiple_ensembles(\n",
    "            queries:dict,\n",
    "            conn:pyesgf.search.connection.SearchConnection,\n",
    "            verbose:bool=False\n",
    "):\n",
    "    '''\n",
    "    Takes a queries dictionary in the same form as make_multiple_queries. Carries out said queries\n",
    "    and then requests confirmation from the user to proceed. Following confirmation, continues to\n",
    "    download each ensemble one by one\n",
    "    '''\n",
    "    contexts = make_multiple_queries(queries, conn)\n",
    "    successfully_downloaded = set()\n",
    "    encountered_errors = set()\n",
    "\n",
    "    response = input('proceed? (y/n)')\n",
    "    if response != 'y':\n",
    "        return\n",
    "\n",
    "    for config in contexts:\n",
    "\n",
    "        print('\\ndownloading next config:', *config)\n",
    "        context = contexts[config]\n",
    "        downloads = download_ensemble(context, verbose)\n",
    "        for dataset in downloads:\n",
    "            successfully_downloaded |= dataset['success']\n",
    "            encountered_errors |= dataset['errors']\n",
    "\n",
    "    print('\\nall downloads now complete. successfully downloaded {} out of {} datasets.'.format(\n",
    "                len(successfully_downloaded),\n",
    "                len(successfully_downloaded)+len(encountered_errors)\n",
    "    ))\n",
    "    print('a full list of datasets omitted due to errors is available below:\\n')\n",
    "    print(*encountered_errors, sep='\\n')\n",
    "\n",
    "# pull the trigger\n",
    "download_multiple_ensembles(queries=queries, conn=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_for_corrupt(path_to_data):\n",
    "    '''\n",
    "    Very ugly function to verify all datasets have been downloaded properly and\n",
    "    check for any files that may be corrupt.\n",
    "    '''\n",
    "\n",
    "    path = os.path.join(path_to_data, 'cordex', 'EUR-11')\n",
    "    variables = [var for var in os.listdir(path) if not '.DS_Store' in var]\n",
    "    errors = []\n",
    "\n",
    "    for variable in variables:\n",
    "        new_path = os.path.join(path, variable)\n",
    "        experiments = [ex for ex in os.listdir(new_path) if not '.DS_Store' in ex]\n",
    "        for experiment in experiments:\n",
    "            new2path = os.path.join(new_path, experiment, 'r1i1p1')\n",
    "            gcms = [gcm for gcm in os.listdir(new2path) if not '.DS_Store' in gcm]\n",
    "            for gcm in gcms:\n",
    "                new3path = os.path.join(new2path, gcm)\n",
    "                rcms = [rcm for rcm in os.listdir(new3path) if not '.DS_Store' in rcm]\n",
    "                for rcm in rcms:\n",
    "                    new4path = os.path.join(new3path, rcm)\n",
    "                    filenames = os.listdir(new4path)\n",
    "                    filepaths = [os.path.join(new4path, filename) for filename in filenames if '.DS_Store' not in filename]\n",
    "                    try:\n",
    "                        xr.open_mfdataset(filepaths)\n",
    "                    except Exception:\n",
    "                        errors.append(new4path)\n",
    "\n",
    "    print(*errors, sep='\\n')\n",
    "\n",
    "check_for_corrupt(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esgf-pyclient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc2a42817589bfc3038401c8f2a535846950842d49a9d58b22efec9ebac8d5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
